# The following python script uses Selenium to web scrape the official premier league website to retrieve booking event data. 
# This is currently only set up to retrieve a single game's data and the code needs to be changed to loop through all games in a season.
# Once a whole season's worth of data has been retrieved, ML techniques could be used to predict the likelihood of bookings occurring within future games.

import requests
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from selenium.webdriver import ActionChains
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.support.ui import Select

from time import sleep, time
import pandas as pd
import warnings
import numpy as np
from datetime import datetime
import json
import time

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

import time
from selenium import webdriver
from selenium.webdriver.common.by import By

base_url = f'https://www.premierleague.com/match/74911'
browser = webdriver.Chrome("#############################")

browser.get(base_url)

browser.implicitly_wait(10)

pop_up = browser.find_element(By.XPATH, "//button[text() = 'Accept All Cookies']")
time.sleep(1)
pop_up.click()

count_of_divs = len(browser.find_elements(By.XPATH, '//*[@id="mainContent"]/div/section[2]/div[2]/section/div[3]/div/div/div[6]/div/div'))-2 

eventsdf = []

for i in range(1, count_of_divs):
    timeevent = browser.find_element(By.XPATH, '//*[@id="mainContent"]/div/section[2]/div[2]/section/div[3]/div/div/div[6]/div/div[{}]'.format(i)).text
    eventelement = browser.find_element(By.XPATH, '//*[@id="mainContent"]/div/section[2]/div[2]/section/div[3]/div/div/div[6]/div/div[{}]/span[1]'.format(i))
    
    try:
        eventelement.click()
    except Exception as e:
        print(f"Failed to click event element at index {i}: {e}")
        continue

    eventplayername = browser.find_element(By.XPATH, '//*[@id="mainContent"]/div/section[2]/div[2]/section/div[3]/div/div/div[6]/div/div[{}]/div/div/div/div/a'.format(i)).text
    timeevent = timeevent.split('\n')
    eventplayername = eventplayername.split('.')[1].strip().split('\n')[0]
    events_merged = [timeevent[0]] + timeevent[1:] + [eventplayername]
    eventsdf.append(events_merged)

pd.DataFrame(eventsdf, columns=['EventType', 'Time', 'Unit', 'Player'])
